#!/bin/bash

# Wait for instruqt bootstrap
until [ -f /opt/instruqt/bootstrap/host-bootstrap-completed ]; do
  sleep 1
done

set -euxo pipefail

set-workdir /root

# Shell conveniences
cat >> ~/.bashrc << 'EOF'
alias k=kubectl
complete -F __start_kubectl k
source /etc/bash_completion
EOF

# Start k3d cluster (pre-installed in image)
if command -v k3d >/dev/null 2>&1; then
  k3d cluster start my-k8s-cluster 2>/dev/null || \
  k3d cluster create my-k8s-cluster --wait
fi

kubectl wait --for=condition=Ready nodes --all --timeout=120s

echo "=== Installing Gateway API CRDs (v1.4.0) ==="
kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.4.0/standard-install.yaml

echo "=== Installing Enterprise AgentGateway CRDs ==="
helm upgrade -i --create-namespace \
  --namespace agentgateway-system \
  --version 2.1.1 \
  enterprise-agentgateway-crds \
  oci://us-docker.pkg.dev/solo-public/enterprise-agentgateway/charts/enterprise-agentgateway-crds

echo "=== Installing Enterprise AgentGateway Control Plane ==="
helm upgrade -i -n agentgateway-system \
  enterprise-agentgateway \
  oci://us-docker.pkg.dev/solo-public/enterprise-agentgateway/charts/enterprise-agentgateway \
  --version 2.1.1 \
  --set-string licensing.licenseKey=${AGENTGATEWAY_LICENSE_KEY} \
  --wait --timeout 120s

kubectl -n agentgateway-system rollout status deployment/enterprise-agentgateway --timeout=120s

echo "=== Installing Solo Enterprise UI (v0.3.4) ==="
helm upgrade -i management \
  oci://us-docker.pkg.dev/solo-public/solo-enterprise-helm/charts/management \
  --namespace agentgateway-system \
  --version 0.3.4 \
  --set cluster="mgmt-cluster" \
  --set products.agentgateway.enabled=true \
  --wait --timeout 180s

echo "Waiting for UI pods..."
kubectl -n agentgateway-system wait --for=condition=Ready pod -l app=solo-enterprise-ui --timeout=180s || true
kubectl -n agentgateway-system wait --for=condition=Ready pod -l app.kubernetes.io/name=clickhouse --timeout=180s || true

echo "=== Configuring Tracing ==="
kubectl apply -f- <<EOF
apiVersion: enterpriseagentgateway.solo.io/v1alpha1
kind: EnterpriseAgentgatewayParameters
metadata:
  name: tracing
  namespace: agentgateway-system
spec:
  rawConfig:
    config:
      tracing:
        otlpEndpoint: grpc://solo-enterprise-telemetry-collector.agentgateway-system.svc.cluster.local:4317
        otlpProtocol: grpc
        randomSampling: true
EOF

echo "=== Creating AgentGateway Proxy with Tracing ==="
kubectl apply -f- <<EOF
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: agentgateway-proxy
  namespace: agentgateway-system
spec:
  gatewayClassName: enterprise-agentgateway
  infrastructure:
    parametersRef:
      name: tracing
      group: enterpriseagentgateway.solo.io
      kind: EnterpriseAgentgatewayParameters
  listeners:
  - protocol: HTTP
    port: 8080
    name: http
    allowedRoutes:
      namespaces:
        from: All
EOF

# Wait for the proxy pod
sleep 10
kubectl -n agentgateway-system wait --for=condition=Available deployment/agentgateway-proxy --timeout=120s || true

echo "=== Setting up port-forward services ==="

# Port-forward for the agentgateway proxy (port 8080)
cat <<SVCEOF > /etc/systemd/system/agentgateway-proxy.service
[Unit]
Description=AgentGateway Proxy Port Forward
After=cloud-final.service multi-user.target
[Service]
Restart=always
RestartSec=5s
Environment="KUBECONFIG=/root/.kube/config"
ExecStart=/usr/local/bin/kubectl -n agentgateway-system port-forward deployment/agentgateway-proxy 8080:8080 --address 0.0.0.0
[Install]
WantedBy=multi-user.target
SVCEOF

# Port-forward for the Solo UI (port 4000 â†’ 80)
cat <<SVCEOF > /etc/systemd/system/solo-ui.service
[Unit]
Description=Solo Enterprise UI Port Forward
After=cloud-final.service multi-user.target
[Service]
Restart=always
RestartSec=5s
Environment="KUBECONFIG=/root/.kube/config"
ExecStart=/usr/local/bin/kubectl -n agentgateway-system port-forward svc/solo-enterprise-ui 4000:80 --address 0.0.0.0
[Install]
WantedBy=multi-user.target
SVCEOF

systemctl daemon-reload
systemctl enable agentgateway-proxy solo-ui
systemctl start agentgateway-proxy solo-ui

echo "=== Deploying mock LLM backend ==="
cat <<'K8SEOF' | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: mock-llm-server
  namespace: default
data:
  server.py: |
    #!/usr/bin/env python3
    import json, http.server, socketserver

    class Handler(http.server.BaseHTTPRequestHandler):
        def do_GET(self):
            if self.path == "/health":
                self.send_response(200)
                self.send_header('Content-Type', 'application/json')
                self.end_headers()
                self.wfile.write(b'{"status":"ok"}')
            else:
                self.send_response(404)
                self.end_headers()

        def do_POST(self):
            length = int(self.headers.get('Content-Length', 0))
            body = self.rfile.read(length).decode('utf-8')
            try:
                req = json.loads(body)
            except:
                req = {"messages": [{"role": "user", "content": body}]}

            user_msg = "Hello!"
            if "messages" in req:
                for msg in reversed(req["messages"]):
                    if msg.get("role") == "user":
                        user_msg = msg.get("content", "Hello!")
                        break

            response = {
                "id": "mock-001",
                "object": "chat.completions",
                "model": req.get("model", "mock-gpt-4"),
                "choices": [{"index": 0, "message": {"role": "assistant", "content": f"I received your message. You said: {user_msg}\n\nHere is my response."}, "finish_reason": "stop"}],
                "usage": {"prompt_tokens": 20, "completion_tokens": 30, "total_tokens": 50}
            }

            resp = json.dumps(response).encode()
            self.send_response(200)
            self.send_header('Content-Type', 'application/json')
            self.send_header('Content-Length', str(len(resp)))
            self.end_headers()
            self.wfile.write(resp)

        def log_message(self, fmt, *args): pass

    socketserver.TCPServer(("", 8080), Handler).serve_forever()
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mock-llm
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mock-llm
  template:
    metadata:
      labels:
        app: mock-llm
    spec:
      containers:
        - name: mock-llm
          image: python:3.11-slim
          command: ["python3", "/app/server.py"]
          ports:
            - containerPort: 8080
          volumeMounts:
            - name: server
              mountPath: /app
      volumes:
        - name: server
          configMap:
            name: mock-llm-server
---
apiVersion: v1
kind: Service
metadata:
  name: mock-llm
  namespace: default
spec:
  selector:
    app: mock-llm
  ports:
    - port: 8080
      targetPort: 8080
K8SEOF

kubectl rollout status deployment/mock-llm --timeout=120s

mkdir -p /root/policies

# Create OpenAI API key secret for use in challenges
if [ -n "$OPENAI_API_KEY" ]; then
  echo "export OPENAI_API_KEY=${OPENAI_API_KEY}" >> ~/.bashrc
  kubectl create secret generic openai-secret -n agentgateway-system \
    --from-literal="Authorization=Bearer $OPENAI_API_KEY" \
    --dry-run=client -oyaml | kubectl apply -f -
  echo "=== OpenAI API key secret created ==="
else
  echo "=== WARNING: OPENAI_API_KEY not set, using placeholder ==="
  kubectl create secret generic openai-secret -n agentgateway-system \
    --from-literal="Authorization=Bearer sk-demo-placeholder-key" \
    --dry-run=client -oyaml | kubectl apply -f -
fi

echo "=== Track setup complete (Enterprise AgentGateway + Solo UI + Tracing) ==="
