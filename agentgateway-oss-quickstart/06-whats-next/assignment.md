---
slug: whats-next
id: yss5ivalys9m
type: challenge
title: What's Next â€” Security & Governance
teaser: Discover what AgentGateway Enterprise adds for production AI agent deployments.
tabs:
- id: u0nkuycn4lch
  title: Terminal
  type: terminal
  hostname: server
- id: 8qsvpe3hamxk
  title: Editor
  type: code
  hostname: server
  path: /root
difficulty: ""
enhanced_loading: null
---

# What's Next: Security & Governance

Congratulations! You've built a working AI gateway that routes traffic to multiple LLM providers with full observability. That's a huge step forward from "every agent calls LLMs directly."

But for production deployments, you need more. Let's talk about what comes next.

## What You Built Today

Let's recap what you accomplished:

âœ… **Identified the problem** â€” direct agent-to-LLM calls create security, cost, and visibility gaps

âœ… **Installed AgentGateway OSS** â€” Kubernetes-native, built on Gateway API

âœ… **Created an AI Gateway** â€” single entry point for all agent traffic

âœ… **Multi-provider routing** â€” OpenAI and Anthropic through one gateway

âœ… **Observability** â€” structured logs and Prometheus metrics for every request

## What AgentGateway Enterprise Adds

For production deployments with strict security and compliance requirements, **AgentGateway Enterprise** adds:

### ðŸ”’ Security
- **Prompt injection detection** â€” block malicious prompts before they reach the LLM
- **PII redaction** â€” automatically detect and mask sensitive data in prompts and responses
- **Authentication & authorization** â€” OIDC, JWT, API key validation per agent/team

### ðŸ’° Cost Controls
- **Rate limiting** â€” per agent, per team, per model
- **Token budgets** â€” set daily/weekly/monthly token limits
- **Cost attribution** â€” track spend by team, agent, or project

### ðŸ”§ MCP Gateway
- **MCP tool routing** â€” gateway for Model Context Protocol tool calls
- **Tool authorization** â€” control which agents can call which tools
- **Tool observability** â€” same logging/metrics for tool calls

### ðŸ“Š Advanced Observability
- **Langfuse integration** â€” full prompt/response tracing
- **OpenTelemetry export** â€” send traces to your existing observability stack
- **Cost dashboards** â€” real-time spend tracking across providers

## Create a Recap File

Summarize your learning:

```bash
cat > /root/workshop-recap.txt << 'EOF'
AgentGateway OSS Quickstart - Workshop Recap

What I learned:
1. Direct agent-to-LLM calls create security and visibility gaps
2. AgentGateway provides a Kubernetes-native gateway for AI traffic
3. Built on Gateway API standard (GatewayClass, Gateway, HTTPRoute)
4. Multi-provider routing through a single endpoint
5. Built-in observability with structured logs and Prometheus metrics

Architecture:
  Agent -> AgentGateway (Gateway API) -> LLM Providers

Key Resources:
  - GatewayClass: registers AgentGateway as an implementation
  - Gateway: the actual gateway instance (listeners)
  - Backend: LLM provider connection details + credentials
  - HTTPRoute: routing rules (path-based, header-based)

Next steps:
  - Try with real API keys
  - Explore AgentGateway Enterprise for security features
  - Set up Langfuse for full LLM observability
EOF

cat /root/workshop-recap.txt
```

## Resources

- ðŸ“– [AgentGateway Documentation](https://docs.solo.io/agentgateway/latest/)
- ðŸ’» [AgentGateway GitHub](https://github.com/solo-io/agentgateway)
- ðŸŽ“ [Solo.io Academy](https://academy.solo.io)
- ðŸ’¬ [Solo.io Community Slack](https://slack.solo.io)
- ðŸ“§ [Contact Solo.io](https://www.solo.io/contact) â€” for Enterprise evaluation

## Thank You!

You've seen how AgentGateway brings the same infrastructure patterns we rely on for microservices to the world of AI agents. As agents become a bigger part of your architecture, having a purpose-built gateway isn't optional â€” it's essential.

**Happy gatewaying! ðŸš€**
