#!/bin/bash

# Wait for instruqt bootstrap
until [ -f /opt/instruqt/bootstrap/host-bootstrap-completed ]; do
  sleep 1
done

set -euxo pipefail

set-workdir /root

# Shell conveniences
cat >> ~/.bashrc << 'EOF'
alias k=kubectl
complete -F __start_kubectl k
source /etc/bash_completion
export ENTERPRISE_AGW_VERSION=2.2.0-beta.1
export GATEWAY_IP=localhost
EOF

export ENTERPRISE_AGW_VERSION=2.2.0-beta.1
export GATEWAY_IP=localhost

# Start k3d cluster (pre-installed in image)
if command -v k3d >/dev/null 2>&1; then
  k3d cluster start my-k8s-cluster 2>/dev/null || \
  k3d cluster create my-k8s-cluster --wait
fi

kubectl wait --for=condition=Ready nodes --all --timeout=120s

echo "=== Installing Gateway API CRDs (v1.4.0 experimental) ==="
kubectl apply --server-side -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.4.0/experimental-install.yaml

echo "=== Installing Enterprise AgentGateway CRDs ==="
kubectl create namespace agentgateway-system || true
helm upgrade -i --create-namespace \
  --namespace agentgateway-system \
  --version $ENTERPRISE_AGW_VERSION \
  enterprise-agentgateway-crds \
  oci://us-docker.pkg.dev/solo-public/enterprise-agentgateway/charts/enterprise-agentgateway-crds

echo "=== Installing Enterprise AgentGateway Controller ==="
helm upgrade -i -n agentgateway-system \
  enterprise-agentgateway \
  oci://us-docker.pkg.dev/solo-public/enterprise-agentgateway/charts/enterprise-agentgateway \
  --create-namespace \
  --version $ENTERPRISE_AGW_VERSION \
  --set-string licensing.licenseKey=${AGENTGATEWAY_LICENSE_KEY} \
  --wait --timeout 180s \
  -f -<<HELMEOF
gatewayClassParametersRefs:
  enterprise-agentgateway:
    group: enterpriseagentgateway.solo.io
    kind: EnterpriseAgentgatewayParameters
    name: agentgateway-params
    namespace: agentgateway-system
HELMEOF

kubectl -n agentgateway-system rollout status deployment/enterprise-agentgateway --timeout=120s

echo "=== Installing Solo Enterprise Management UI ==="
helm upgrade -i management \
  oci://us-docker.pkg.dev/solo-public/solo-enterprise-helm/charts/management \
  --namespace agentgateway-system \
  --create-namespace \
  --version 0.3.4 \
  --set cluster="mgmt-cluster" \
  --set products.agentgateway.enabled=true \
  --wait --timeout 180s || true

# Wait for Solo UI pods to start (non-blocking — UI is nice-to-have)
echo "=== Waiting for Solo UI components ==="
kubectl -n agentgateway-system wait --for=condition=Available deployment -l app.kubernetes.io/instance=management --timeout=120s 2>/dev/null || \
  echo "WARNING: Solo UI pods not all ready yet — will continue"

echo "=== Installing Monitoring Stack ==="
helm repo add grafana https://grafana.github.io/helm-charts
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update grafana prometheus-community

# Tempo for tracing
helm upgrade --install tempo \
  grafana/tempo-distributed \
  --namespace monitoring \
  --create-namespace \
  --wait --timeout 180s \
  --values - <<EOF
minio:
  enabled: false
traces:
  otlp:
    grpc:
      enabled: true
    http:
      enabled: true
  zipkin:
    enabled: false
  jaeger:
    thriftHttp:
      enabled: false
  opencensus:
    enabled: false
EOF

# Prometheus + Grafana
helm upgrade --install grafana-prometheus \
  prometheus-community/kube-prometheus-stack \
  --version 80.4.2 \
  --namespace monitoring \
  --wait --timeout 180s \
  --values - <<EOF
alertmanager:
  enabled: false
grafana:
  adminPassword: "admin"
  service:
    type: ClusterIP
    port: 3000
  additionalDataSources:
    - name: Tempo
      type: tempo
      access: proxy
      url: "http://tempo-query-frontend.monitoring.svc.cluster.local:3200"
      uid: 'local-tempo-uid'
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "1"
      searchNamespace: monitoring
nodeExporter:
  enabled: false
prometheus:
  service:
    type: ClusterIP
  prometheusSpec:
    ruleSelectorNilUsesHelmValues: false
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
EOF

# PodMonitor for AgentGateway metrics
kubectl apply -f- <<EOF
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: agentgateway-metrics
  namespace: agentgateway-system
spec:
  namespaceSelector:
    matchNames:
      - agentgateway-system
  podMetricsEndpoints:
    - port: metrics
  selector:
    matchLabels:
      app.kubernetes.io/name: agentgateway
EOF

# Install AgentGateway Grafana Dashboard (from workshop repo if available, otherwise skip)
if [ -f /tmp/agentgateway-grafana-dashboard-v1.json ]; then
  kubectl create configmap agentgateway-dashboard \
    --from-file=agentgateway-overview.json=/tmp/agentgateway-grafana-dashboard-v1.json \
    --namespace monitoring \
    --dry-run=client -o yaml | \
  kubectl label --local -f - \
    grafana_dashboard="1" \
    --dry-run=client -o yaml | \
  kubectl apply -f -
fi

echo "=== Configuring EnterpriseAgentgatewayParameters ==="
kubectl apply -f- <<'EOF'
apiVersion: enterpriseagentgateway.solo.io/v1alpha1
kind: EnterpriseAgentgatewayParameters
metadata:
  name: agentgateway-params
  namespace: agentgateway-system
spec:
  sharedExtensions:
    extauth:
      enabled: true
      deployment:
        spec:
          replicas: 1
    ratelimiter:
      enabled: true
      deployment:
        spec:
          replicas: 1
    extCache:
      enabled: true
      deployment:
        spec:
          replicas: 1
  logging:
    level: info
  service:
    spec:
      type: LoadBalancer
  rawConfig:
    config:
      logging:
        fields:
          add:
            jwt: 'jwt'
            request.body: json(request.body)
            response.body: json(response.body)
        format: json
      tracing:
        otlpProtocol: grpc
        otlpEndpoint: http://tempo-distributor.monitoring.svc.cluster.local:4317
        randomSampling: 'true'
        fields:
          add:
            gen_ai.operation.name: '"chat"'
            gen_ai.system: "llm.provider"
            gen_ai.prompt: 'llm.prompt'
            gen_ai.completion: 'llm.completion.map(c, {"role":"assistant", "content": c})'
            gen_ai.request.model: "llm.requestModel"
            gen_ai.response.model: "llm.responseModel"
            gen_ai.usage.completion_tokens: "llm.outputTokens"
            gen_ai.usage.prompt_tokens: "llm.inputTokens"
  deployment:
    spec:
      replicas: 1
      template:
        spec:
          containers:
          - name: agentgateway
            resources:
              requests:
                cpu: 300m
                memory: 128Mi
EOF

# Create a separate tracing config for Solo UI telemetry collector
kubectl apply -f- <<'EOF'
apiVersion: enterpriseagentgateway.solo.io/v1alpha1
kind: EnterpriseAgentgatewayParameters
metadata:
  name: tracing
  namespace: agentgateway-system
spec:
  rawConfig:
    config:
      tracing:
        otlpEndpoint: grpc://solo-enterprise-telemetry-collector.agentgateway-system.svc.cluster.local:4317
        otlpProtocol: grpc
        randomSampling: true
EOF

echo "=== Creating Gateway Resource ==="
kubectl apply -f- <<EOF
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: agentgateway
  namespace: agentgateway-system
spec:
  gatewayClassName: enterprise-agentgateway
  infrastructure:
    parametersRef:
      name: tracing
      group: enterpriseagentgateway.solo.io
      kind: EnterpriseAgentgatewayParameters
  listeners:
    - name: http
      port: 8080
      protocol: HTTP
      allowedRoutes:
        namespaces:
          from: All
EOF

# Wait for proxy
sleep 10
kubectl -n agentgateway-system wait --for=condition=Available deployment -l app.kubernetes.io/name=agentgateway --timeout=180s || true

echo "=== Setting up port-forward services ==="

cat <<SVCEOF > /etc/systemd/system/agentgateway-proxy.service
[Unit]
Description=AgentGateway Proxy Port Forward
After=cloud-final.service multi-user.target
[Service]
Restart=always
RestartSec=5s
Environment="KUBECONFIG=/root/.kube/config"
ExecStart=/usr/local/bin/kubectl -n agentgateway-system port-forward svc/agentgateway 8080:8080 --address 0.0.0.0
[Install]
WantedBy=multi-user.target
SVCEOF

cat <<SVCEOF > /etc/systemd/system/grafana.service
[Unit]
Description=Grafana Port Forward
After=cloud-final.service multi-user.target
[Service]
Restart=always
RestartSec=5s
Environment="KUBECONFIG=/root/.kube/config"
ExecStart=/usr/local/bin/kubectl -n monitoring port-forward svc/grafana-prometheus 3000:3000 --address 0.0.0.0
[Install]
WantedBy=multi-user.target
SVCEOF

cat <<SVCEOF > /etc/systemd/system/solo-ui.service
[Unit]
Description=Solo Enterprise UI Port Forward
After=cloud-final.service multi-user.target
[Service]
Restart=always
RestartSec=5s
Environment="KUBECONFIG=/root/.kube/config"
ExecStart=/usr/local/bin/kubectl -n agentgateway-system port-forward svc/solo-enterprise-ui 4000:80 --address 0.0.0.0
[Install]
WantedBy=multi-user.target
SVCEOF

systemctl daemon-reload
systemctl enable agentgateway-proxy grafana solo-ui
systemctl start agentgateway-proxy grafana solo-ui

# Store OpenAI key
if [ -n "${OPENAI_API_KEY:-}" ]; then
  echo "export OPENAI_API_KEY=${OPENAI_API_KEY}" >> ~/.bashrc
  kubectl create secret generic openai-secret -n agentgateway-system \
    --from-literal="Authorization=Bearer $OPENAI_API_KEY" \
    --dry-run=client -oyaml | kubectl apply -f -
  echo "=== OpenAI API key stored ==="
else
  echo "=== WARNING: OPENAI_API_KEY not set ==="
fi

echo "=== Track setup complete ==="
