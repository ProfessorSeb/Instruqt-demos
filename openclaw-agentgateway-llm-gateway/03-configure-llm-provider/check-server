#!/bin/bash
set -euxo pipefail

if ! kubectl get secret openai-api-key -n agentgateway-system &>/dev/null; then
  fail-message "Secret 'openai-api-key' not found. Create it with: kubectl create secret generic openai-api-key --namespace agentgateway-system --from-literal=apiKey=\"\$OPENAI_API_KEY\""
fi

if ! kubectl get agentgatewaybackend openai -n agentgateway-system &>/dev/null; then
  fail-message "AgentgatewayBackend 'openai' not found. Apply the backend manifest from the assignment."
fi

GW_STATUS=$(kubectl get gateway llm-gateway -n agentgateway-system \
  -o jsonpath='{.status.conditions[?(@.type=="Programmed")].status}' 2>/dev/null)
if [ "$GW_STATUS" != "True" ]; then
  fail-message "Gateway 'llm-gateway' is not Programmed yet. Check: kubectl describe gateway llm-gateway -n agentgateway-system"
fi

# Verify traffic flows through the gateway (no auth header — gateway handles it)
HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
  -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"gpt-4o-mini","messages":[{"role":"user","content":"ping"}]}' \
  --max-time 15)

if [ "$HTTP_CODE" != "200" ]; then
  fail-message "Gateway returned HTTP $HTTP_CODE. Traffic is not flowing through AgentGateway yet. Check the AIRoute is configured correctly."
fi

# Save the route manifest if not already saved
[ -f /root/openai-route.yaml ] || \
  kubectl get aiRoute openai-route -n agentgateway-system -o yaml > /root/openai-route.yaml

echo "Challenge 3 passed — LLM traffic is flowing through AgentGateway."
